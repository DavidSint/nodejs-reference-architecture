"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[8354],{3905:function(e,n,t){t.d(n,{Zo:function(){return p},kt:function(){return h}});var o=t(7294);function r(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function a(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);n&&(o=o.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,o)}return t}function i(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?a(Object(t),!0).forEach((function(n){r(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):a(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function s(e,n){if(null==e)return{};var t,o,r=function(e,n){if(null==e)return{};var t,o,r={},a=Object.keys(e);for(o=0;o<a.length;o++)t=a[o],n.indexOf(t)>=0||(r[t]=e[t]);return r}(e,n);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(o=0;o<a.length;o++)t=a[o],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(r[t]=e[t])}return r}var l=o.createContext({}),c=function(e){var n=o.useContext(l),t=n;return e&&(t="function"==typeof e?e(n):i(i({},n),e)),t},p=function(e){var n=c(e.components);return o.createElement(l.Provider,{value:n},e.children)},u={inlineCode:"code",wrapper:function(e){var n=e.children;return o.createElement(o.Fragment,{},n)}},d=o.forwardRef((function(e,n){var t=e.components,r=e.mdxType,a=e.originalType,l=e.parentName,p=s(e,["components","mdxType","originalType","parentName"]),d=c(t),h=r,m=d["".concat(l,".").concat(h)]||d[h]||u[h]||a;return t?o.createElement(m,i(i({ref:n},p),{},{components:t})):o.createElement(m,i({ref:n},p))}));function h(e,n){var t=arguments,r=n&&n.mdxType;if("string"==typeof e||r){var a=t.length,i=new Array(a);i[0]=d;var s={};for(var l in n)hasOwnProperty.call(n,l)&&(s[l]=n[l]);s.originalType=e,s.mdxType="string"==typeof e?e:r,i[1]=s;for(var c=2;c<a;c++)i[c]=t[c];return o.createElement.apply(null,i)}return o.createElement.apply(null,t)}d.displayName="MDXCreateElement"},926:function(e,n,t){t.r(n),t.d(n,{frontMatter:function(){return s},contentTitle:function(){return l},metadata:function(){return c},toc:function(){return p},default:function(){return d}});var o=t(7462),r=t(3366),a=(t(7294),t(3905)),i=["components"],s={sidebar_position:8},l="Scaling and Multi-threading",c={unversionedId:"functional-components/scaling-multi-threading",id:"functional-components/scaling-multi-threading",isDocsHomePage:!1,title:"Scaling and Multi-threading",description:"Node.js is said to be single-threaded. While not quite true, it reflects that",source:"@site/docs/functional-components/scaling-multi-threading.md",sourceDirName:"functional-components",slug:"/functional-components/scaling-multi-threading",permalink:"/nodejs-reference-architecture/functional-components/scaling-multi-threading",editUrl:"https://github.com/nodeshift/nodejs-reference-architecture/docs/functional-components/scaling-multi-threading.md",tags:[],version:"current",sidebarPosition:8,frontMatter:{sidebar_position:8},sidebar:"tutorialSidebar",previous:{title:"Node.js Versions and Container Images",permalink:"/nodejs-reference-architecture/functional-components/nodejs-versions-images"},next:{title:"Static assets",permalink:"/nodejs-reference-architecture/functional-components/static-assets"}},p=[{value:"Recommended Components",id:"recommended-components",children:[]},{value:"Guidance",id:"guidance",children:[]}],u={toc:p};function d(e){var n=e.components,t=(0,r.Z)(e,i);return(0,a.kt)("wrapper",(0,o.Z)({},u,t,{components:n,mdxType:"MDXLayout"}),(0,a.kt)("h1",{id:"scaling-and-multi-threading"},"Scaling and Multi-threading"),(0,a.kt)("p",null,"Node.js is said to be ",(0,a.kt)("inlineCode",{parentName:"p"},"single-threaded"),". While not quite true, it reflects that\nmost work is done on a single thread running the event loop. The asynchronous\nnature of JavaScript means that Node.js can handle a larger number of\nconcurrent requests on that single thread."),(0,a.kt)("p",null,"At the same time that does not mean that Node.js applications/solutions are\n",(0,a.kt)("inlineCode",{parentName:"p"},"single-threaded"),". Today's computers provide multiple concurrent threads of\nexecution (either with multiple cores and/or cores that can support\nmultiple concurrent threads of execution) and Node.js applications have\nlong exploited those additional threads by running multiple Node.js instances."),(0,a.kt)("p",null,"Mutiple threads within a single machine can typically either be exploited within\na single process or by starting multiple processes. There are advantages\nand dis-advantages to each."),(0,a.kt)("p",null,"Processes provide better isolation but also lower\nopportunities to share resources and makes communication between threads\nmore costly. While using multiple threads within a process may be able to\nscale more efficiently within a single process it has the hard limit\nof only being able to scale to the resources provided by a single machine."),(0,a.kt)("p",null,"With container based deployments the number of threads available may\nalso be limited, with the assumption that when additional cpu resources\nare needed, additional containers will be created and the load\nspread across those containers."),(0,a.kt)("p",null,"Today's cloud native deployments generally have a goal to be able to\nscale to a level that that cannot be met through by the\nresources/availability that can be achieved on a single machine. This\nnaturally favors scaling by adding additional copies of a container,\neach of which, is typically running a single process."),(0,a.kt)("p",null,"The small footprint and fast startup of Node.js, along with the\nability to handle many concurrent requests without needing multiple\nthreads of execution and synchornization between those threads makes\nit a good fit for todays approach to scaling using containers."),(0,a.kt)("h2",{id:"recommended-components"},"Recommended Components"),(0,a.kt)("p",null,"We don't recommened any specific components at this time."),(0,a.kt)("h2",{id:"guidance"},"Guidance"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},"when possible applications should be decomposed so that a\nrequest to a single container will need no more than single\nthread of execution in order to complete in a reasonable time.\nWhen necessary to achive this, consider futher decomposing\nthe application. If this is not reasonable,\n",(0,a.kt)("a",{parentName:"p",href:"https://nodejs.org/api/worker_threads.html"},"WorkerThreads"),"\nare recommended versus multiple processes in the same container.")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},"delegate management of the containers supporting\nthe application and the routing of requests to those containers\nto the highest layer possible. For example, if the application\nis deployed to kubernetes, do not use tools like the\n",(0,a.kt)("a",{parentName:"p",href:"https://nodejs.org/api/cluster.html"},"Cluster API")," to manage\nrequests within a container, instead rely on the facilities\nprovided by kubernetes. In our experience this has been\njust as efficient in terms of machine resources and allows\nbetter scaling."),(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},"Avoid blocking the event loop for a prolonged period\nof time. If you have a mix of request types where some are long\nrunning, consider moving the long running requests so that they\nexecute in their own set of containers in order to enable better\nscaling. However, even once moved it often makes sense to use\n",(0,a.kt)("a",{parentName:"li",href:"https://nodejs.org/api/worker_threads.html"},"WorkerThreads")," to\nrun the long running request in order to\navoid blocking the main event loop. This is to prevent\nlong running requests on the main event loop from stalling\nrequests to health monitoring, metrics and similar endpoints\nthat need to be supported by a containter."))),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},"When using ",(0,a.kt)("a",{parentName:"p",href:"https://nodejs.org/api/worker_threads.html"},"WorkerThreads"),"\nmake sure you pool worker threads (for example\nby using something like ",(0,a.kt)("a",{parentName:"p",href:"https://www.npmjs.com/package/piscina"},"piscina"),"\nand ensure you preserve ascync context for requests with\n",(0,a.kt)("a",{parentName:"p",href:"https://nodejs.org/api/async_hooks.html#async_hooks_class_asyncresource"},"AsyncResource"),"\nif you don't use an existing pooling library like piscina which\ndoes this for you.")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},(0,a.kt)("a",{parentName:"p",href:"https://nodejs.org/api/worker_threads.html"},"WorkerThreads"),"\nmay also be appropriate if your application\nmust run as a single process (for example a desktop application). In these\ncases it is known that you cannot scale beyond the resources of the single\nmachine and it is often preferrable to have the application show up\nas a single processes versus many individual processes."))))}d.isMDXComponent=!0}}]);