"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[9488],{3905:function(e,t,o){o.d(t,{Zo:function(){return u},kt:function(){return h}});var r=o(7294);function n(e,t,o){return t in e?Object.defineProperty(e,t,{value:o,enumerable:!0,configurable:!0,writable:!0}):e[t]=o,e}function a(e,t){var o=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),o.push.apply(o,r)}return o}function c(e){for(var t=1;t<arguments.length;t++){var o=null!=arguments[t]?arguments[t]:{};t%2?a(Object(o),!0).forEach((function(t){n(e,t,o[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(o)):a(Object(o)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(o,t))}))}return e}function i(e,t){if(null==e)return{};var o,r,n=function(e,t){if(null==e)return{};var o,r,n={},a=Object.keys(e);for(r=0;r<a.length;r++)o=a[r],t.indexOf(o)>=0||(n[o]=e[o]);return n}(e,t);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(r=0;r<a.length;r++)o=a[r],t.indexOf(o)>=0||Object.prototype.propertyIsEnumerable.call(e,o)&&(n[o]=e[o])}return n}var s=r.createContext({}),l=function(e){var t=r.useContext(s),o=t;return e&&(o="function"==typeof e?e(t):c(c({},t),e)),o},u=function(e){var t=l(e.components);return r.createElement(s.Provider,{value:t},e.children)},d={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},p=r.forwardRef((function(e,t){var o=e.components,n=e.mdxType,a=e.originalType,s=e.parentName,u=i(e,["components","mdxType","originalType","parentName"]),p=l(o),h=n,m=p["".concat(s,".").concat(h)]||p[h]||d[h]||a;return o?r.createElement(m,c(c({ref:t},u),{},{components:o})):r.createElement(m,c({ref:t},u))}));function h(e,t){var o=arguments,n=t&&t.mdxType;if("string"==typeof e||n){var a=o.length,c=new Array(a);c[0]=p;var i={};for(var s in t)hasOwnProperty.call(t,s)&&(i[s]=t[s]);i.originalType=e,i.mdxType="string"==typeof e?e:n,c[1]=i;for(var l=2;l<a;l++)c[l]=o[l];return r.createElement.apply(null,c)}return r.createElement.apply(null,o)}p.displayName="MDXCreateElement"},3211:function(e,t,o){o.r(t),o.d(t,{frontMatter:function(){return i},contentTitle:function(){return s},metadata:function(){return l},toc:function(){return u},default:function(){return p}});var r=o(7462),n=o(3366),a=(o(7294),o(3905)),c=["components"],i={sidebar_position:7},s="Code Coverage",l={unversionedId:"docs/development/code-coverage",id:"docs/development/code-coverage",isDocsHomePage:!1,title:"Code Coverage",description:"Code coverage is a software testing metric that determines the number of lines of code that is successfully validated under a test procedure, which in turn, helps in analyzing how comprehensively a software is verified.",source:"@site/docs/docs/development/code-coverage.md",sourceDirName:"docs/development",slug:"/docs/development/code-coverage",permalink:"/nodejs-reference-architecture/docs/development/code-coverage",editUrl:"https://github.com/nodeshift/nodejs-reference-architecture/docs/docs/development/code-coverage.md",tags:[],version:"current",sidebarPosition:7,frontMatter:{sidebar_position:7},sidebar:"tutorialSidebar",previous:{title:"Typescript",permalink:"/nodejs-reference-architecture/docs/development/typescript"},next:{title:"REST APIs Development",permalink:"/nodejs-reference-architecture/docs/functional-components/apifirst"}},u=[{value:"Recommended Modules",id:"recommended-modules",children:[]},{value:"Where to focus on higher coverage",id:"where-to-focus-on-higher-coverage",children:[]},{value:"Coverage percentage thresholds",id:"coverage-percentage-thresholds",children:[]},{value:"OpenSource Projects",id:"opensource-projects",children:[]},{value:"Output Formats",id:"output-formats",children:[]}],d={toc:u};function p(e){var t=e.components,o=(0,n.Z)(e,c);return(0,a.kt)("wrapper",(0,r.Z)({},d,o,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("h1",{id:"code-coverage"},"Code Coverage"),(0,a.kt)("p",null,"Code coverage is a software testing metric that determines the number of lines of code that is successfully validated under a test procedure, which in turn, helps in analyzing how comprehensively a software is verified."),(0,a.kt)("p",null,"To measure the lines of code that are actually exercised by test runs, various criteria are taken into consideration. Outlined below are a few important coverage criteria are used."),(0,a.kt)("p",null,"Function Coverage \u2013 The functions in the source code that are called and executed at least once."),(0,a.kt)("p",null,"Statement Coverage \u2013 The number of statements that have been successfully validated in the source code."),(0,a.kt)("p",null,"Path Coverage \u2013 The flows containing a sequence of controls and conditions that have worked well at least once."),(0,a.kt)("p",null,"Branch or Decision Coverage \u2013 The decision control structures (loops, for example) that have executed fine."),(0,a.kt)("p",null,"Condition Coverage \u2013 The Boolean expressions that are validated and that executes both TRUE and FALSE as per the test runs."),(0,a.kt)("h2",{id:"recommended-modules"},"Recommended Modules"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"https://www.npmjs.com/package/nyc"},"nyc"),": the most popular code-coverage tool; the successor CLI for Istanbul"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"https://www.npmjs.com/package/jest"},"jest"),": Code coverage using the ",(0,a.kt)("inlineCode",{parentName:"li"},"--coverage")," flag")),(0,a.kt)("h1",{id:"guidance"},"Guidance"),(0,a.kt)("h2",{id:"where-to-focus-on-higher-coverage"},"Where to focus on higher coverage"),(0,a.kt)("p",null,"For applications, the coverage should be driven by the key user stories/key paths that the application can take.  For modules, it is important to cover all public APIs."),(0,a.kt)("h2",{id:"coverage-percentage-thresholds"},"Coverage percentage thresholds"),(0,a.kt)("p",null,"For those projects that are new, and just starting out, a good percentage threshold is about 70%.  This is because with new projects, it is easier to add tests while creating the application."),(0,a.kt)("p",null,"If adding coverage to a project that is older that might not have any coverage yet, it might be a little harder since adding tests to an older project with technical debt can be a challenge, especially for someone new coming into the project.  In this case a good percentage threshold is about 30%.  It is also our experience that when adding coverage to a older code base, focusing on the key user stories will give you the best return on investment.  Focusing on the Path and/or Branch/Decision coverage will also maximize the investment on getting to 30%."),(0,a.kt)("h2",{id:"opensource-projects"},"OpenSource Projects"),(0,a.kt)("p",null,"For OpenSource projects, it might be helpful to post the results of the coverage to an external service, such as coveralls and creating an issue related to increasing the code coverage could be a way to attract contributors to the project."),(0,a.kt)("p",null,"It is also common to report the coverage increase or decrease percentage during a PR CI run.  In our experience, it is best to use this information in a code review rather than blocking a merge."),(0,a.kt)("p",null,"Code coverage should never block a production deployment"),(0,a.kt)("h2",{id:"output-formats"},"Output Formats"),(0,a.kt)("p",null,"A common output format is the lcov format, which the recommeneded modules can produce."))}p.isMDXComponent=!0}}]);